                           RETAIL STORE SALES DATA

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum,avg

# Create a Spark session
spark = SparkSession.builder.appName("Retail Sales Analysis").getOrCreate()

# Sample data
data = [
    (1, "Apple", "Groceries", 0.50, 10, "2023-09-01"),
    (2, "T-shirt", "Clothing", 15.00, 2, "2023-09-01"),
    (3, "Notebook", "Stationery", 2.00, 5, "2023-09-02"),
    (4, "Banana", "Groceries", 0.30, 12, "2023-09-02"),
    (5, "Laptop", "Electronics", 800.00, 1, "2023-09-03"),
    (6, "Pants", "Clothing", 25.00, 3, "2023-09-03"),
    (7, "Headphones", "Electronics", 100.00, 2, "2023-09-04"),
    (8, "Pen", "Stationery", 1.00, 10, "2023-09-04"),
    (9, "Orange", "Groceries", 0.60, 8, "2023-09-05"),
    (10, "Sneakers", "Clothing", 50.00, 1, "2023-09-05")
]

# Define the schema
columns = ["transaction_id", "product_name", "category", "price", "quantity", "sales_date"]

# Create DataFrame
df = spark.createDataFrame(data, schema=columns)
df.show()

# 1.Calculate the total revenue per category
total_revenue_per_category = df.withColumn(
    "revenue", col("price") * col("quantity")
).groupBy("category").agg(
    sum("revenue").alias("total_revenue"))

# Show the result
total_revenue_per_category.show()


2. Filter Transactions Where the Total Sales Amount is Greater Than $100
#Filter the dataset to show only transactions where the total sales amount (price * quantity) is greater than $100.

filtered_transactions = df.withColumn(
    "total_sales_amount", col("price") * col("quantity")).filter(col("total_sales_amount") > 100)

filtered_transactions.show()


#3. Find the Most Sold Product
#Identify the product with the highest total quantity sold across all transactions.

most_sold_product = df.groupBy("product_name").agg(
    sum("quantity").alias("total_quantity_sold")
).orderBy(col("total_quantity_sold").desc()).limit(1)

most_sold_product.show()


#4. Calculate the Average Price per Product Category
#Group the data by category and calculate the average price of products in each category.

average_price_per_category = df.groupBy("category").agg(
    sum("price").alias("total_price"),
    sum("quantity").alias("total_quantity")
).withColumn(
    "average_price", col("total_price") / col("total_quantity")
).select("category", "average_price")
average_price_per_category.show()


#5. Find the Top 3 Highest Grossing Products
#Calculate the total revenue for each product and identify the top 3 products that generated the most revenue.

revenue_per_product = df.withColumn(
    "revenue", col("price") * col("quantity")).groupBy("product_name").agg(
    sum("revenue").alias("total_revenue")).orderBy(col("total_revenue").desc()).limit(3)
revenue_per_product.show()


6. Calculate the Total Number of Items Sold per Day
#Group the data by sales_date and calculate the total quantity of items sold for each day.

items_sold_per_day = df.groupBy("sales_date").agg(
    sum("quantity").alias("total_items_sold"))
items_sold_per_day.show()


#7. Identify the Product with the Lowest Price in Each Category
#For each category, identify the product with the lowest price.

from pyspark.sql.window import Window
from pyspark.sql.functions import row_number

window_spec = Window.partitionBy("category").orderBy("price")

# Add a row number to each product within its category
products_with_row_number = df.withColumn(
    "row_number", row_number().over(window_spec))
lowest_price_per_category = products_with_row_number.filter(col("row_number") == 1).select("category", "product_name", "price")
lowest_price_per_category.show()


#8. Calculate the Total Revenue for Each Product
#Group the data by product_name and calculate the total revenue generated by each product.

total_revenue_per_product = df.withColumn(
    "revenue", col("price") * col("quantity")).groupBy("product_name").agg(
    sum("revenue").alias("total_revenue"))
total_revenue_per_product.show()


#9. Find the Total Sales per Day for Each Category
#Group the data by sales_date and category to calculate the total sales for each category per day.

total_sales_per_day_per_category = df.withColumn(
    "sales_amount", col("price") * col("quantity")).groupBy("sales_date", "category").agg(
    sum("sales_amount").alias("total_sales"))
total_sales_per_day_per_category.show()


#10. Create a New Column for Discounted Price
#Add a new column called discounted_price that applies a 10% discount to the original price for each product ( price * 0.9 ).

df_with_discount = df.withColumn(
    "discounted_price", col("price") * 0.9)
df_with_discount.show()
