1: Creating DataFrame from Scratch**
#1. Create a DataFrame with the following columns: `"Product"`, `"Category"`, `"Price"`, and `"Quantity"`. Use the following data:
#   - Product: `['Laptop', 'Mouse', 'Monitor', 'Keyboard', 'Phone']`
#   - Category: `['Electronics', 'Accessories', 'Electronics', 'Accessories', 'Electronics']`
#   - Price: `[80000, 1500, 20000, 3000, 40000]`
#   - Quantity: `[10, 100, 50, 75, 30]`
#2. Print the DataFrame.

import pandas as pd

data= {
    "Product": ['Laptop', 'Mouse', 'Monitor', 'Keyboard', 'Phone'],
    "Category": ['Electronics', 'Accessories', 'Electronics', 'Accessories', 'Electronics'],
    "Price": [80000, 1500, 20000, 3000, 40000],
    "Quantity": [10, 100, 50, 75, 30]
}
df = pd.DataFrame(data)
print(df)



# 2: Basic DataFrame Operations**
#. Display the first 3 rows of the DataFrame.
#2. Display the column names and index of the DataFrame.
#3. Display a summary of statistics (mean, min, max, etc.) for the numeric columns in the DataFrame.

print(df.head(3))
print(df.columns)
print(df.index)
print(df.describe())



#3.Selecting Data**
#1. Select and display the `"Product"` and `"Price"` columns.
#2. Select rows where the `"Category"` is `"Electronics"` and print them.
print(df[['Product', 'Price']])
electronics_df = df[df['Category'] == 'Electronics']
print(electronics_df)



#4. Filtering Data**
#1. Filter the DataFrame to display only the products with a price greater than `10,000`.
#2. Filter the DataFrame to show only products that belong to the `"Accessories"` category and have a quantity greater than `50`.
expensive_products = df[df['Price'] > 10000]
print(expensive_products)

accessories_with_quantity = df[(df['Category'] == 'Accessories') & (df['Quantity'] > 50)]
print(accessories_with_quantity)



#5. Adding and Removing Columns**
#1. Add a new column `"Total Value"` which is calculated by multiplying `"Price"` and `"Quantity"`.
#2. Drop the `"Category"` column from the DataFrame and print the updated DataFrame.
df['Total Value'] = df['Price'] * df['Quantity']
print(df)

df = df.drop(columns=['Category'])
print(df)



#6.Sorting Data**
#1. Sort the DataFrame by `"Price"` in descending order.
#2. Sort the DataFrame by `"Quantity"` in ascending order, then by `"Price"` in descending order (multi-level sorting).
sorted_by_price = df.sort_values(by='Price', ascending=False)
print(sorted_by_price)

sorted_by_quantity_and_price = df.sort_values(by=['Quantity', 'Price'], ascending=[True, False])
print(sorted_by_quantity_and_price)



#7. Grouping Data**
#1. Group the DataFrame by `"Category"` and calculate the total quantity for each category.
#2. Group by `"Category"` and calculate the average price for each category.
#total_quantity_by_category = df.groupby('Category')['Quantity'].sum()
#print(total_quantity_by_category)

#average_price_by_category = df.groupby('Category')['Price'].mean()
#print(average_price_by_category)



#8.Handling Missing Data**
#1. Introduce some missing values in the `"Price"` column by assigning `None` to two rows.
#2. Fill the missing values with the mean price of the available products.
#3. Drop any rows where the `"Quantity"` is less than `50`.
df.loc[1, 'Price'] = None
df.loc[4, 'Price'] = None
print(df)

mean_price = df['Price'].mean()
df['Price'].fillna(mean_price)

df = df[df['Quantity'] >= 50]
print(df)



#9. Apply Custom Functions**
#1. Apply a custom function to the `"Price"` column that increases all prices by 5%.
#2. Create a new column `"Discounted Price"` that reduces the original price by 10%.
def increase_price(price):
    return price * 1.05
df['Price'] = df['Price'].apply(increase_price)

df['Discounted Price'] = df['Price'] * 0.90
print(df)



#10. Merging DataFrames**
#1. Create another DataFrame with columns `"Product"` and `"Supplier"`, and merge it with the original DataFrame based on the `"Product"` column.
supplier_data = {
    "Product": ['Laptop', 'Mouse', 'Monitor', 'Keyboard', 'Phone'],
    "Supplier": ['Supplier A', 'Supplier B', 'Supplier C', 'Supplier A', 'Supplier D']
}
supplier_df = pd.DataFrame(supplier_data)
merged_df = pd.merge(df, supplier_df, on='Product')
print("Merged DataFrame:")
print(merged_df)



#11.Pivot Tables**
#1. Create a pivot table that shows the total quantity of products for each category and product combination.
#pivot_table = pd.pivot_table(df, values='Quantity',index='Category', columns='Product', aggfunc='sum', fill_value=0)
#print(pivot_table)



#12. Concatenating DataFrames**
#1. Create two separate DataFrames for two different stores with the same columns (`"Product"`, `"Price"`, `"Quantity"`).
#2. Concatenate these DataFrames to create a combined inventory list.
store1_data = {
    "Product": ['Laptop', 'Mouse', 'Monitor'],
    "Price": [80000, 1500, 20000],
    "Quantity": [10, 100, 50]
}
store2_data = {
    "Product": ['Keyboard', 'Phone', 'Tablet'],
    "Price": [3000, 40000, 25000],
    "Quantity": [75, 30, 20]
}
store1_df = pd.DataFrame(store1_data)
store2_df = pd.DataFrame(store2_data)
combined_inventory = pd.concat([store1_df, store2_df], ignore_index=True)

print("Combined Inventory List:")
print(combined_inventory)



#13. Working with Dates**
#1. Create a DataFrame with a `"Date"` column that contains the last 5 days starting from today.
#2. Add a column `"Sales"` with random values for each day.
#3. Find the total sales for all days combined.

from datetime import datetime,timedelta
today = datetime.now()
dates = [today - timedelta(days=i) for i in range(5)]
dates.reverse()
df = pd.DataFrame({"Date": dates})

df['Sales'] = pd.Series(range(100, 1050, 200))
print(df)

total_sales = df['Sales'].sum()
print(total_sales)



#14. Reshaping Data with Melt**
#1. Create a DataFrame with columns `"Product"`, `"Region"`, `"Q1_Sales"`, `"Q2_Sales"`.
#2. Use `pd.melt()` to reshape the DataFrame so that it has columns `"Product"`, `"Region"`, `"Quarter"`, and `"Sales"`.
data = {
    "Product": ['Laptop', 'Mouse', 'Monitor'],
    "Region": ['North', 'South', 'East'],
    "Q1_Sales": [10000, 1500, 3000],
    "Q2_Sales": [12000, 1800, 3500]
}
df = pd.DataFrame(data)
melted_df = pd.melt(df, id_vars=['Product', 'Region'],
                    var_name='Quarter',
                    value_name='Sales')
melted_df['Quarter'] = melted_df['Quarter'].str.replace('_Sales', '')

print("Reshaped DataFrame:")
print(melted_df)



#15. Reading and Writing Data**
#1. Read the data from a CSV file named `products.csv` into a DataFrame.
#2. After performing some operations (e.g., adding a new column or modifying values), write the DataFrame back to a new CSV file named `updated_products.csv`.
df = pd.read_csv('products.csv')
print(df)
df['Discounted_Price'] = df['Price'] * 0.90
df['Quantity'] = df['Quantity'] + 10
print(df)
df.to_csv('updated_products.csv', index=False)



#16. Renaming Columns**
#1. Given a DataFrame with columns `"Prod"`, `"Cat"`, `"Price"`, `"Qty"`, rename the columns to `"Product"`, `"Category"`, `"Price"`, and `"Quantity"`.
#2. Print the renamed DataFrame.

data={
    "Prod": ['Laptop', 'Mouse', 'Monitor', 'Keyboard', 'Phone'],
    "Cat": ['Electronics', 'Accessories', 'Electronics', 'Accessories', 'Electronics'],
    "Price": [80000, 1500, 20000, 3000, 40000],
    "Qty": [10, 100, 50, 75, 30]
}
df = pd.DataFrame(data)
df.rename(columns={
    "Prod": "Product",
    "Cat": "Category",
    "Qty": "Quantity"
}, inplace=True)

print("Renamed DataFrame:")
print(df)



#17.Creating a MultiIndex DataFrame**
#1. Create a DataFrame using a MultiIndex (hierarchical index) with two levels: `"Store"` and `"Product"`. The DataFrame should have columns `"Price"` and `"Quantity"`, representing the price and quantity of products in different stores.
#2. Print the MultiIndex DataFrame.
arrays = [
    ['Store_A', 'Store_A', 'Store_A', 'Store_B', 'Store_B', 'Store_C', 'Store_C', 'Store_C'],
    ['Laptop', 'Mouse', 'Monitor', 'Keyboard', 'Phone', 'Laptop', 'Mouse', 'Monitor']
]

index = pd.MultiIndex.from_arrays(arrays, names=('Store', 'Product'))

data = {
    'Price': [80000, 1500, 20000, 3000, 40000, 85000, 1600, 22000],
    'Quantity': [10, 100, 50, 75, 30, 20, 150, 45]
}

df = pd.DataFrame(data, index=index)

print("MultiIndex DataFrame:")
print(df)



#18. Resample Time-Series Data**
#1. Create a DataFrame with a `"Date"` column containing a range of dates for the past 30 days and a `"Sales"` column with random values.
#2. Resample the data to show the total sales by week.
df = pd.DataFrame({
    'Date': pd.date_range(start=pd.Timestamp.now() - pd.DateOffset(days=30), periods=30, freq='D'),
    'Sales': pd.Series(range(30)) * 10 + 100
})
weekly_sales = df.set_index('Date').resample('W').sum()

print(weekly_sales)




#19.Handling Duplicates**
#1. Given a DataFrame with duplicate rows, identify and remove the duplicate rows.
#2. Print the cleaned DataFrame.
data = {
    'A': [1, 2, 2, 4, 5, 5],
    'B': ['a', 'b', 'b', 'd', 'e', 'e'],
    'C': [10, 20, 20, 40, 50, 50]
}
df = pd.DataFrame(data)
duplicates = df.duplicated()
df_cleaned = df.drop_duplicates()
print(df_cleaned)




#20.: Correlation Matrix**
#1. Create a DataFrame with numeric data representing different features (e.g., `"Height"`, `"Weight"`, `"Age"`, `"Income"`).
#2. Compute the correlation matrix for the DataFrame.
#3. Print the correlation matrix.
data = {
    'Height': pd.Series(pd.util.testing.rands_array(10, 100).astype(int)) % 50 + 150,
    'Weight': pd.Series(pd.util.testing.rands_array(10, 100).astype(int)) % 50 + 50,
    'Age': pd.Series(pd.util.testing.rands_array(10, 100).astype(int)) % 47 + 18,
    'Income': pd.Series(pd.util.testing.rands_array(10, 100).astype(int)) % 70000 + 30000
}
df = pd.DataFrame(data)

correlation_matrix = df.corr()
print("Correlation Matrix:")
print(correlation_matrix)




#21. Cumulative Sum and Rolling Windows**
#1. Create a DataFrame with random sales data for each day over the last 30 days.
#2. Calculate the cumulative sum of the sales and add it as a new column `"Cumulative Sales"`.
#3. Calculate the rolling average of sales over the past 7 days and add it as a new column `"Rolling Avg"`.
date_range = pd.date_range(start=pd.Timestamp.now() - pd.DateOffset(days=30), periods=30, freq='D')
sales_data = {
    'Date': date_range,
    'Sales': pd.Series(range(30)) * 5 + 100  # Random sales data
}
df = pd.DataFrame(sales_data)
df.set_index('Date', inplace=True)
df['Cumulative Sales'] = df['Sales'].cumsum()
df['Rolling Avg'] = df['Sales'].rolling(window=7).mean()
print(df)



#22. String Operations**
#1. Create a DataFrame with a column `"Names"` containing values like `"John Doe"`, `"Jane Smith"`, `"Sam Brown"`.
#2. Split the `"Names"` column into two separate columns: `"First Name"` and `"Last Name"`.
#3. Convert the `"First Name"` column to uppercase.
data = {
    'Names': ['John Doe', 'Jane Smith', 'Sam Brown']
}
df = pd.DataFrame(data)
df[['First Name', 'Last Name']] = df['Names'].str.split(' ', 1, expand=True)
df['First Name'] = df['First Name'].str.upper()
print(df)




#23.Conditional Selections with `np.where`**
#1. Create a DataFrame with columns `"Employee"`, `"Age"`, and `"Department"`.
#2. Create a new column `"Status"` that assigns `"Senior"` to employees aged 40 or above and `"Junior"` to employees below 40 using `np.where()`.
import numpy as np
data = {
    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],
    'Age': [34, 45, 29, 50, 36],
    'Department': ['HR', 'Finance', 'IT', 'Management', 'Marketing']
}
df = pd.DataFrame(data)
df['Status'] = np.where(df['Age'] >= 40, 'Senior', 'Junior')
print(df)




#24. Slicing DataFrames**
#1. Given a DataFrame with data on `"Products"`, `"Category"`, `"Sales"`, and `"Profit"`, slice the DataFrame to display:
 #  - The first 10 rows.
  # - All rows where the `"Category"` is `"Electronics"`.
   #- Only the `"Sales"` and `"Profit"` columns for products with sales greater than 50,000.

data = {
    'Products': ['Laptop', 'Smartphone', 'Tablet', 'Monitor', 'Printer', 'Headphones', 'Mouse', 'Keyboard', 'Webcam', 'Speakers', 'Charger', 'USB Drive', 'External Hard Drive', 'Docking Station', 'Router'],
    'Category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics', 'Accessories', 'Accessories', 'Accessories', 'Accessories', 'Accessories', 'Electronics', 'Electronics', 'Electronics', 'Electronics', 'Networking'],
    'Sales': [120000, 85000, 30000, 45000, 60000, 15000, 25000, 30000, 12000, 20000, 25000, 30000, 75000, 40000, 35000],
    'Profit': [20000, 15000, 5000, 8000, 10000, 3000, 5000, 6000, 2500, 4000, 5000, 6000, 15000, 7000, 6000]
}
df = pd.DataFrame(data)
first_10_rows = df.head(10)
print(first_10_rows)

electronics_category = df[df['Category'] == 'Electronics']
print(electronics_category)

high_sales = df[df['Sales'] > 50000][['Sales', 'Profit']]
print(high_sales)




#25. Concatenating DataFrames Vertically and Horizontally**
#1. Create two DataFrames with identical columns `"Employee"`, `"Age"`, `"Salary"`, but different rows (e.g., one for employees in `"Store A"` and one for employees in `"Store B"`).
#2. Concatenate the DataFrames vertically to create a combined DataFrame.
#3. Now create two DataFrames with different columns (e.g., `"Employee"`, `"Department"` and `"Employee"`, `"Salary"`) and concatenate them horizontally based on the common `"Employee"` column.
df_store_a = pd.DataFrame({
    'Employee': ['Alice', 'Bob', 'Charlie'],
    'Age': [34, 45, 29],
    'Salary': [70000, 80000, 50000]
})

df_store_b = pd.DataFrame({
    'Employee': ['David', 'Eva', 'Frank'],
    'Age': [50, 36, 28],
    'Salary': [90000, 60000, 55000]
})

df_combined = pd.concat([df_store_a, df_store_b], ignore_index=True)

print("Combined DataFrame (Vertical Concatenation):")
print(df_combined)

df_department = pd.DataFrame({
    'Employee': ['Alice', 'Bob', 'Charlie', 'David'],
    'Department': ['HR', 'Finance', 'IT', 'Management']
})

df_salary = pd.DataFrame({
    'Employee': ['Alice', 'Bob', 'Charlie', 'Eva'],
    'Salary': [70000, 80000, 50000, 60000]
})
df_merged = pd.merge(df_department, df_salary, on='Employee', how='left')

print("Merged DataFrame (Horizontal Concatenation):")
print(df_merged)




#26. Exploding Lists in DataFrame Columns**
#1. Create a DataFrame with a column `"Product"` and a column `"Features"` where each feature is a list (e.g., `["Feature1", "Feature2"]`).
#2. Use the `explode()` method to create a new row for each feature in the list, so each product-feature pair has its own row.
data = {
    'Product': ['Product1', 'Product2', 'Product3'],
    'Features': [['Feature1', 'Feature2'], ['Feature3'], ['Feature4', 'Feature5', 'Feature6']]
}
df = pd.DataFrame(data)
print(df)

df_exploded = df.explode('Features')
print(df_exploded)




#27.Using `.map()` and `.applymap()`**
#1. Given a DataFrame with columns `"Product"`, `"Price"`, and `"Quantity"`, use `.map()` to apply a custom function to increase `"Price"` by 10% for each row.
#2. Use `.applymap()` to format the numeric values in the DataFrame to two decimal places.

data = {
    'Product': ['Product1', 'Product2', 'Product3'],
    'Price': [100, 150, 200],
    'Quantity': [10, 20, 30]
}
df = pd.DataFrame(data)
def increase_price(price):
    return price * 1.10
df['Price'] = df['Price'].map(increase_price)
print(df)

df_formatted = df.applymap(lambda x: f"{x:.2f}" if isinstance(x, (int, float)) else x)
print(df_formatted)




#28.Combining `groupby()` with `apply()`**
#1. Create a DataFrame with `"City"`, `"Product"`, `"Sales"`, and `"Profit"`.
#2. Group by `"City"` and apply a custom function to calculate the profit margin (Profit/Sales) for each city.
data = {
    'City': ['New York', 'New York', 'Los Angeles', 'Los Angeles', 'Chicago', 'Chicago'],
    'Product': ['Laptop', 'Smartphone', 'Tablet', 'Monitor', 'Printer', 'Headphones'],
    'Sales': [120000, 85000, 30000, 45000, 60000, 15000],
    'Profit': [20000, 15000, 5000, 8000, 10000, 3000]
}
df = pd.DataFrame(data)
def calculate_profit_margin(group):
    group['Profit Margin'] = group['Profit'] / group['Sales']
    return group

df_with_margin = df.groupby('City').apply(calculate_profit_margin)
print("DataFrame with Profit Margin for each City:")
print(df_with_margin)